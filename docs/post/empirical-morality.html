<!doctype html><html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>rybl.net | Moral Empiricism</title><link rel="stylesheet" href="/asset/style/common.css"/><link rel="stylesheet" href="/asset/style/util.css"/><link rel="stylesheet" href="/asset/style/Top.css"/><link rel="stylesheet" href="/asset/style/Tag.css"/><link rel="stylesheet" href="/asset/style/ParsedDate.css"/><link rel="stylesheet" href="/asset/style/Header.css"/><link rel="stylesheet" href="/asset/style/Footer.css"/><link rel="stylesheet" href="/asset/style/Raindrops.css"/><link rel="stylesheet" href="/asset/style/Markdown.css"/><script src="/asset/script/Top.js"></script><script src="/asset/script/parallax_on_scroll.js"></script><link rel="stylesheet" href="/asset/style/Post.css"/><link rel="stylesheet" href="/asset/style/PostNameCard.css"/><script src="/asset/script/Post.js"></script></head><body><svg style="width:0;height:0;position:absolute;"><filter id="nightsky"><feTurbulence id="nightsky-turbulence" type="fractalNoise" baseFrequency="0.1" numOctaves="1" stitchTiles="stitch" result="noise"></feTurbulence><feTile in="noise" result="tiled_noise"></feTile><feOffset id="nightsky-turbulenceOffset" in="tiled_noise" dx="0" dy="0" result="offset_noise"></feOffset><feComponentTransfer in="offset_noise" result="stars_pattern"><feFuncA type="discrete" tableValues="0 0 0 1"></feFuncA></feComponentTransfer><feColorMatrix in="stars_pattern" type="matrix" values="1 0 0 0 0
                          0 1 0 0 0
                          0 0 1 0 0
                          0.333 0.333 0.333 0 0"></feColorMatrix></filter><filter id="warp"><feTurbulence id="turbulence-generator" type="fractalNoise" baseFrequency="0.01 0.04" numOctaves="1" seed="2" result="turbulence"></feTurbulence><feDisplacementMap in="SourceGraphic" in2="turbulence" scale="100" xChannelSelector="R" yChannelSelector="G" result="displacement"></feDisplacementMap></filter><filter id="gooey"><feGaussianBlur in="SourceGraphic" stdDeviation="15" result="blur"></feGaussianBlur><feColorMatrix in="blur" mode="matrix" values="1 0 0 0 0  0 1 0 0 0  0 0 1 0 0  0 0 0 18 -7" result="goo"></feColorMatrix><feBlend in="SourceGraphic" in2="goo"></feBlend></filter></svg><div id="background"></div><header><div class="logo"><img src="/asset/image/profile.png"/></div><div class="name"><div class="website_name"><a href="/">rybl.net</a></div><div class="separator"></div><div class="resource_shortname"><div>2ELD5YTSPcs0tWGL2qfoGlDCCoOOdyuQ5+9HOg0Y4o0iYtllms5VGl7yAjfIdjZ4ixucV+I7wnz0pDsKcuC7Bg==</div></div></div><div class="menu"><a href="/index.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon lucide lucide-library-icon lucide-library"><path d="m16 6 4 14"></path><path d="M12 6v14"></path><path d="M8 8v12"></path><path d="M4 4v16"></path></svg></a><a href="/Tags.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon lucide lucide-tag-icon lucide-tag"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg></a><a href="/About.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon lucide lucide-info-icon lucide-info"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg></a><a href="/Profiles.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe-icon lucide-globe"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg></a><a href="/ReferencesGraphPage.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-orbit-icon lucide-orbit"><path d="M20.341 6.484A10 10 0 0 1 10.266 21.85"></path><path d="M3.659 17.516A10 10 0 0 1 13.74 2.152"></path><circle cx="12" cy="12" r="3"></circle><circle cx="19" cy="5" r="2"></circle><circle cx="5" cy="19" r="2"></circle></svg></a><a href="/Signature.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-fingerprint-icon lucide-fingerprint"><path d="M12 10a2 2 0 0 0-2 2c0 1.02-.1 2.51-.26 4"></path><path d="M14 13.12c0 2.38 0 6.38-1 8.88"></path><path d="M17.29 21.02c.12-.6.43-2.3.5-3.02"></path><path d="M2 12a10 10 0 0 1 18-6"></path><path d="M2 16h.01"></path><path d="M21.8 16c.2-2 .131-5.354 0-6"></path><path d="M5 19.5C5.5 18 6 15 6 12a6 6 0 0 1 .34-2"></path><path d="M8.65 22c.21-.66.45-1.32.57-2"></path><path d="M9 6.8a6 6 0 0 1 9 5.2v2"></path></svg></a></div></header><main><div class="content"><div class="PostNameCard without_nameImage"><h1 class="layer2"><a href="/post/empirical-morality.html">Moral Empiricism</a></h1></div><ol class="tableOfContents">
<li>
<p><a href="#Moral%20Theories%20and%20Metaethics" title="Moral Theories and Metaethics">Moral Theories and Metaethics</a></p>
</li>
<li>
<p><a href="#Metaethical%20Justifications%20for%20Ethical%20Theories" title="Metaethical Justifications for Ethical Theories">Metaethical Justifications for Ethical Theories</a></p>
<ol>
<li>
<p><a href="#Moral%20Intuitionism" title="Moral Intuitionism">Moral Intuitionism</a></p>
<ol>
<li><a href="#Accepting%20Moral%20Relativism" title="Accepting Moral Relativism">Accepting Moral Relativism</a></li>
</ol>
</li>
<li>
<p><a href="#Hierarchies%20of%20Moral%20Intuitions" title="Hierarchies of Moral Intuitions">Hierarchies of Moral Intuitions</a></p>
</li>
</ol>
</li>
<li>
<p><a href="#Moral%20Constructivism" title="Moral Constructivism">Moral Constructivism</a></p>
</li>
<li>
<p><a href="#Moral%20Empiricism" title="Moral Empiricism">Moral Empiricism</a></p>
</li>
<li>
<p><a href="#References" title="References">References</a></p>
</li>
</ol>
<div class="headingWrapper"><h2 id="Moral%20Theories%20and%20Metaethics"><a href="http://localhost:3000/post/empirical-morality.html#Moral%20Theories%20and%20Metaethics">Moral Theories and Metaethics</a></h2></div>
<p>A <em>moral claim</em> is a true judgment of the morality of an action i.e. whether or
not an action <em>ought</em> to be taken. An <em>ethical theory</em> is a theory that explains
how moral claims are true (i.e. justifications for moral claims). A meta ethical
theory (or <em>theory of morality</em>) is a theory of which justifications for moral
claims are valid (i.e. explanations for the basis of morality). For example,
<em>utilitarianism</em> is an ethical theory — it gives a framework for calculating
which actions are moral. But utilitarianism is not a metaethical theory since it
does not explain why the calculations correctly map onto morality. Nihilism is a
metaethical theory since it is about which justifications for moral claims are
valid, in particular, that there are no valid justifications.</p>
<p>This essay focuses on the metaethical side of the topic of morality, and I will
present a metaethical theory: Moral Empiricism.</p>
<p>To lead up to the metaethical questions, first consider what sorts of moral
claims there are. At first glance, there are three kinds of moral claims to
consider:</p>
<ol>
<li>moral claims that are justified by some moral claims</li>
<li>moral claims that are justified by only non-moral claims</li>
<li>moral claims that need no justification</li>
</ol>
<p>Note that this classification is epistemic, <em>not</em> metaphysical (This is because
it uses “justified because of” as opposed to “true because of”. I am avoiding
the metaphysics of
<a href="https://plato.stanford.edu/entries/truthmakers/" class="LinkWithIcon"><img src="/asset/icon/plato_stanford_edu" class="icon"><span class="label">truthmakers</span></a>). In this way,
the classification of moral claims into type 1 or type 2 depends on which
ethical theory is used as a premise, whereas a metaphysical classification would
not. For example, the truth that murder is wrong is a type 1 moral claim under
the premise of Judaism (via the 10 commandments), but it is a type 2 moral claim
under a utilitarianism (via a utility calculation).</p>
<p>A type 1 moral claims are the most common in everyday life. It's morally wrong
to hurt people and steal things because, for example, hurting people causes
people to experience suffering (which is morally wrong) and stealing things
causes innocent people to be worse off (which is morally wrong). Most of the
time, these sorts of justifications are plenty, because it’s obvious, for some
reasons, that, for example, causing people to experience suffering is morally
wrong.</p>
<p>A type 2 moral claim appeals to some non-moral domain of truth for
justification. For example, the moral claim that murder is wrong could be
justified by the fact that murder is against the 10 commandments. This
justification appeals to premise that the 10 commandments accurately reflect
morality, which is a non-moral premise.</p>
<p>Note that religious justifications aren't the only ones that fall under type 2.
As another example, utilitarianism is a moral framework where the morality of an
action is judged by its expected utility yield. A utilitarian could justify the
moral claim that murder is wrong by saying that murder reduces expected utility.
This justification appeals to the premise that utilitarianism is true, which is
a non-moral premise.</p>
<p>A type 3 moral claim does no make any appeal at all to a justification (moral or
otherwise ) -- it is an axiomatic truth. For example, a non-religious person
could believe in all the same moral claims as a religious person, but the
non-religious person could differ from the religious person by positing the
moral claims that were justified by religion as axioms instead. Trivial moral
claims (such as “A is moral because A is moral”) that are true in any ethical
theory are all type 3 moral claims. But it seems that non-trivial type 3 moral
claims are normal inaccessible, since if they have no justification then how
could anyone be convinced of a type 3 moral claim if they did not already know
it to be true?</p>
<p>In order to figure the <em>foundations</em> for moral claims, it is sufficient to
consider only type 2 and 3 moral claims; a chain of type 1 moral claims must
eventually appeal to a type 2 or 3 moral claim or else the moral framework is
inconsistent because it contains justification cycles or infinite justification
chains.</p>
<p>Next, how many type 2 and type 3 moral claims are there? There is of course the
entire class of trivial moral claims that are true in any ethical theory. But,
for any ethical theory that yields more than trivial moral claims, it must also
yield some type 2 moral claims.</p>
<p>Type 2 truths are a good place to consider some curious metaethical aspects of
ethical theories. For the example of murder being wrong in utilitarianism, the
chain of justification usually goes something like this:</p>
<p>Murder is wrong because:</p>
<ol>
<li>A murder produces X net utility (by calculation)</li>
<li>X is negative (by inspection)</li>
<li>A murder is an action that produces negative net utility (by 1, 2)</li>
<li>An action that produces negative net utility is morally wrong because:
<ol>
<li>Utilitarianism is true (because of course)</li>
</ol>
</li>
<li>Murder is morally wrong (by 3, 4)</li>
</ol>
<p>In this chain, 4 is a type 2 moral claim, and 4.1 is a metaethical claim.</p>
<p>The key maneuver here is the claim that utilitarianism is true. Since this is a
metaethical claim, it must be justified become introducing moral grounds for
justification — it would be a vicious regress to claim that utilitarianism is
true by appealing to another ethical theory, since now that (second order)
ethical theory would now need the same sort of justification. Regardless, this
is usually how that point 4.1 would be justified:</p>
<p>Utilitarianism is true because:</p>
<ul>
<li>What, you’d prefer if there was more suffering rather than less!? It’s
utilitarianism is clearly the most moral system, and you would be immoral to
appose it.</li>
</ul>
<p>Or, replace “utilitarianism” with your most favored/hated ethical theory.</p>
<div class="headingWrapper"><h2 id="Metaethical%20Justifications%20for%20Ethical%20Theories"><a href="http://localhost:3000/post/empirical-morality.html#Metaethical%20Justifications%20for%20Ethical%20Theories">Metaethical Justifications for Ethical Theories</a></h2></div>
<div class="headingWrapper"><h3 id="Moral%20Intuitionism"><a href="http://localhost:3000/post/empirical-morality.html#Moral%20Intuitionism">Moral Intuitionism</a></h3></div>
<p>One popular way to approach metaethical justification is to rely heavily on type
3 moral claims. In particular, a particular ethical theory is justified by how
exactly it includes a pre-determined set of type 3 moral claims that are <em>just
true</em>. For example, if we all <em>just know</em> that murder is wrong, then any ethical
theory that says murder is morally good is weekend and any ethical theory that
says murder is morally bad is strengthened in terms of metaethical
justification.</p>
<p>This style of metaethical justification is <em>moral intuitionism</em> which states
that an ethical theory is justified by how exactly is complies with type 3 moral
claims that we <em>just know</em> to be true (i.e. our moral intuitions).</p>
<p>As (implicitly) popular as it is, moral intuitionism has some steep drawbacks.</p>
<ul>
<li>It appears that there are many moral intuitions that are not universally
shared. So, a moral relativist must choose one:
<ul>
<li>Accept <em>moral relativism</em>: moral truths are subjective (as opposed to
objective), so different people can correctly believe in contradictory moral
truths.</li>
<li>Reject moral relativism, which requires an account for how and why there is
something inferior about the intuitions of those that do not share the true
moral intuitions.</li>
</ul>
</li>
<li>The correspondence between moral intuitions and moral truths is not obvious.
In fact, there are plenty of cases where the same person’s moral intuitions
are internally inconsistent (especially over time). So, in order to disallow
inconsistent ethical theories, a moral intuitionist must account for which
intuitions do and don’t correspond to moral truths and why.</li>
</ul>
<div class="headingWrapper"><h4 id="Accepting%20Moral%20Relativism"><a href="http://localhost:3000/post/empirical-morality.html#Accepting%20Moral%20Relativism">Accepting Moral Relativism</a></h4></div>
<p>The simplest response to these drawbacks is to accept moral relativism, but this
has two very steep drawbacks. To accept moral relativism is to claim that all
moral claims are subjective i.e. are implicitly prefixed with “for me, …” The
issue with this is that, when people actually do make moral claims, the claims
are not very sensical with implicit subjectivity. For example, typically when a
person claims “murder is wrong,” they are not claiming that it is wrong just for
<em>them</em> to murder, but that it is wrong for <em>anyone</em> to murder. Additionally,
they are not claiming murder is wrong from their own perspective (though that is
also true), but that murder is wrong from any perspective. To figure (with these
clarifications) that they still mean their claim subjectively seems to be some
sort of misunderstanding. So the first steep drawback of moral relativism is to
accept this, which implies that the vast majority of moral claims are either
false (since objective moral claims are false) or fundamentally misunderstood by
their speakers (they think they are making an objective claim, but they are
actually making a subjective one). Under this, a moral relativist must reject
basically everything currently established about morality, yielding just that
each person has their own correct, personal, and entirely unique ethical theory
judged by their intuitions.</p>
<p>The second steep drawback of moral relativism is that it contradicts the usual
meaning of morality itself. It is generally accepted for people to have
contradicting yet subjectively-true beliefs (e.g. opinions about subjective
preferences). But it seems almost nonsensical to say that there can be
contradictory yet true claims about what <em>ought</em> to be done. For example,
suppose that person P1 believes that action A ought to be done and person P2
believes that action A ought to not be done. The subjective truths are that A
ought to be done (from P1’s point of view) and A ought not to be done (from P2’s
point of view). These are not contradictory, because of the different points of
view. The moral relativist claims that the moral conversation stops here, as
there is no way to settle this difference — there is no such thing as an
objective point of view by which to view moral truths, even though (in an
objective reality) only A or not A can actually be done.</p>
<p>// TODO: really get into why moral relativism is objectionable, and justify
meta*ethical justifications here.</p>
<div class="headingWrapper"><h3 id="Hierarchies%20of%20Moral%20Intuitions"><a href="http://localhost:3000/post/empirical-morality.html#Hierarchies%20of%20Moral%20Intuitions">Hierarchies of Moral Intuitions</a></h3></div>
<p>If a moral intuitionist rejects moral relativism (i.e. they maintain that there
are objective moral truths) then they must account for how to decide which moral
intuition are (most likely to be) correct and why. In this direction, presenting
a decision process is easy, but justifying it is very difficult.</p>
<p>// TODO: use this? For example, a moral intuitionist could say that those
intuitions that are had in calm, low-pressure circumstances with lots of time to
deliberate with other people are the most likely to be correct. This seems
reasonable enough, since we can all relate to the how panicked, high-pressure
circumstances can often lead to regrettable choices on any topic.</p>
<p>Here a moral intuitionist can make a metaphysical distinction that hasn’t been
specified yet:</p>
<ul>
<li>Moral intuitions are <em>the basis</em> on which ethical theories are justified. In
this case, there is something metaphysically special about moral intuitions.
So there needs to be no justification for a choice of which moral intuitions
are true, since the true moral intuitions simply are the definitional basis of
metaethical justification. This an unpopular position, and devolves into
arguing about the definitional foundations of morality and metaethical
justification, so it seems like a dead end.</li>
<li>Moral intuitions are <em>indicators</em> of which ethical theories are justified. In
this case, moral intuitions are playing a merely epistemic role, helping
people have knowledge of moral truths (in some way). So, it is easy for the
moral intuitionist to explain how the circumstances for intuitions that we
trust the most in general about subjects that we can objectively verify (such
as logical and many physical facts) can also be reasonably trusted the most
also for moral intuitions for the same reasons. However, an account of how
moral intuitions given any knowledge at all about moral truths is still
difficult — how do we <em>know</em> that moral intuitions are such indicators? This
also seems like a fairly dead end, with the only escape being a vicious
regress of appealing to higher-level intuitions that lower-level intuitions
are indicators of the truth.</li>
</ul>
<p>So altogether, the variety of branches that moral intuitionism provides all seem
to end in weak positions.</p>
<div class="headingWrapper"><h2 id="Moral%20Constructivism"><a href="http://localhost:3000/post/empirical-morality.html#Moral%20Constructivism">Moral Constructivism</a></h2></div>
<p>A tac that is more successful and much more popular than moral intuitionism is
<em>moral constructivism</em>, which is the claim that moral truths are socially
constructed and so don’t have intrinsic truthfulness. In this way, moral truths
are not facts about humans in general or the physical world, but merely facts
about the social organizations of particular humans (and perhaps other things).</p>
<p>Moral constructivism solves a lot of metaethical problems, since it gives an
entire account for how ethical theories are justified, and, even better,
corresponds plausibly to how ethical theories actually are justified. A moral
constructivist says that a society negotiates a ethical theory, through explicit
exchanges, implicit norms, etc., and at any given point there is a fact of the
matter about how that society has organized itself in order to specify a moral
theory.</p>
<p>This sounds an awful lot like moral subjectivism, but it differs very
importantly. Rather than moral truths being subjective <em>to each person</em> via on
their personal moral takes, moral constructivism appeals to an entire society’s
negotiated moral stance, which is something that can be and is agreed upon by
many people (especially in that society).</p>
<p>However, some of the problems of moral subjectivism still do leak through to
some extent, where an individual’s subjective ethical theory is replaced by an
individual society’s ethical theory. There is still the problem of contradicting
the usual meaning of morality itself: two different societies can have clashing
ethical theories that are irreconcilable, and circumstances can arise where
following both ethical theories is impossible. For many societal/cultural
features, this is not a huge surprise or problem. Of course there are societal
differences in how people do things which seem weird when viewed from another
society. But when it comes to morality, the force of “ought” is impossible to
escape. If a society morally condones doing something that another society finds
morally wrong, then there can be a moral obligation for conflict, as each
society views their ethical theory as of course developed within their own
society but still applicable everywhere. A moral constructivist maintains that
we can as a society make moral judgements, but admits that to check to see if
the moral judgements are correct is to do nothing more than check if they follow
morality according to the norms and customs accepted by the society.</p>
<p>And this does not just apply to co-existent societies with contradiction moral
theories. Most people accept that there has been moral progress over at least
the last couple thousand years: today more people have more freedom and better
lives than the people did in earlier times. Yet, for the moral constructivist,
this idea of moral progress is something that only applies to the present, since
the societies of the past would probably not view present society as being more
moral (and many would view it as being much less moral). Never along the arc of
“moral progress” does a moral constructivist see a change from a “worse” ethical
theory to a “better” ethical theory, except from the point of view of our modern
constructed ethical theory by which we judge the past.</p>
<p>This appears to contradict what most people agree on about the claim of moral
progress and what has happened over threat theme period. Usually the claim of
moral progress also include the claim that people in the past we wrong about
certain aspects of morality and right about others. But to the moral
constructivist, those people were not wrong about morality at the time, since
morality <em>was</em> just their socially constructed system of moral rules also at the
time. E.g. There’s nothing morally wrong with slavery <em>at the time</em> and in the
places where is was accepted. Only looking back do we say that slavery <em>is wrong
now</em> according to our modern society’s ethical theory.</p>
<div class="headingWrapper"><h2 id="Moral%20Empiricism"><a href="http://localhost:3000/post/empirical-morality.html#Moral%20Empiricism">Moral Empiricism</a></h2></div>
<p><em>Moral empiricism</em> is the view that the fact of which ethical theory is correct
is merely an <em>empirical</em> fact about <em>human nature</em>.</p>
<p>Moral empiricism is similar to moral relativism in that it admits there is no
ethical theory that is correct in an extra-human objective way. But it avoids
many typical problems of moral relativism because it does not admit inconsistent
ethical theories among humans which is (usually) the relevant group.</p>
<p>Moral empiricism is similar to moral constructivism in that it finds the source
of morality to be human-centric as opposed to the universe in general without
specific reference to humans. But is refines the constructed source of moraltiy
to be in human nature rather than in more superficial societal features such as
political authority, trends in moral sensibilities, etc.</p>
<p>Moral empiricism does not reduce to moral intuitionism, since intuitions are
merely a symptom of human nature. Moral intuitions are not a part of human
nature, but are caused by aspects of humans that are accounted for by the
pattern of human nature. In this way, there can by certain statistical
correlations between moral intuitions and the correct ethical theory as sought
by empirically investigating human nature, since the influences of human nature
can be invariant while other extra-human influences vary.</p>
<p>// TODO: Give a more specific idea of what is included in the pattern "human
nature" e.g. biological patterns over time, social patters over time, etc.</p>
<p>// TODO: Explain why moral empiricism is compelling. Not only does it solve all
these issues, but empirically it should be shown to be most closely in line with
what people mean by "morality"</p>
<p>// TODO: more explanation of moral empiricism, and give examples and
compare/contrast with other (similar) metaethical theories</p>
<p>// TODO: give interesting caveat about how moral empiricism allows for different
ethical theories to be true for pre-humans, post-humans, and also aliens</p>
<p>// TODO: address problem of animals: actually, this is not so hard. We feel
negligible moral sympathy for animal cruelty by other animals than we do for
animal cruelty by humans, so its really about human morality still</p>
<div class="headingWrapper"><h2 id="References"><a href="http://localhost:3000/post/empirical-morality.html#References">References</a></h2></div>
<ul>
<li><a href="https://plato.stanford.edu/entries/truthmakers/" class="LinkWithIcon"><img src="/asset/icon/plato_stanford_edu" class="icon"><span class="label">Truthmakers (Stanford Encyclopedia of Philosophy)</span></a></li>
</ul></div></main><header><div class="menu"><a href="/index.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon lucide lucide-library-icon lucide-library"><path d="m16 6 4 14"></path><path d="M12 6v14"></path><path d="M8 8v12"></path><path d="M4 4v16"></path></svg></a><a href="/Tags.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon lucide lucide-tag-icon lucide-tag"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg></a><a href="/About.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon lucide lucide-info-icon lucide-info"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg></a><a href="/Profiles.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe-icon lucide-globe"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg></a><a href="/ReferencesGraphPage.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-orbit-icon lucide-orbit"><path d="M20.341 6.484A10 10 0 0 1 10.266 21.85"></path><path d="M3.659 17.516A10 10 0 0 1 13.74 2.152"></path><circle cx="12" cy="12" r="3"></circle><circle cx="19" cy="5" r="2"></circle><circle cx="5" cy="19" r="2"></circle></svg></a><a href="/Signature.html" class="item"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-fingerprint-icon lucide-fingerprint"><path d="M12 10a2 2 0 0 0-2 2c0 1.02-.1 2.51-.26 4"></path><path d="M14 13.12c0 2.38 0 6.38-1 8.88"></path><path d="M17.29 21.02c.12-.6.43-2.3.5-3.02"></path><path d="M2 12a10 10 0 0 1 18-6"></path><path d="M2 16h.01"></path><path d="M21.8 16c.2-2 .131-5.354 0-6"></path><path d="M5 19.5C5.5 18 6 15 6 12a6 6 0 0 1 .34-2"></path><path d="M8.65 22c.21-.66.45-1.32.57-2"></path><path d="M9 6.8a6 6 0 0 1 9 5.2v2"></path></svg></a></div><div class="name"><div class="website_name"><a href="/">rybl.net</a></div><div class="separator"></div><div class="resource_shortname"><div>2ELD5YTSPcs0tWGL2qfoGlDCCoOOdyuQ5+9HOg0Y4o0iYtllms5VGl7yAjfIdjZ4ixucV+I7wnz0pDsKcuC7Bg==</div></div></div><div class="logo"><img src="/asset/image/profile.png"/></div></header></body></html>